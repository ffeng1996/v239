---
title: Filter bubbles and affective polarization in user-personalized large language
  model outputs
abstract: Echoing the history of search engines and social media content rankings,
  the advent of large language models (LLMs) has led to a push for increased personalization
  of model outputs to individual users. In the past, personalized recommendations
  and ranking systems have been linked to the development of filter bubbles (serving
  content that may confirm a user’s existing biases) and affective polarization (strong
  negative sentiment towards those with differing views). In this work, we explore
  how prompting a leading large language model, ChatGPT-3.5, with a user’s political
  affiliation prior to asking factual questions about public figures and organizations
  leads to differing results. We observe that left-leaning users tend to receive more
  positive statements about left-leaning political figures and media outlets, while
  right-leaning users see more positive statements about right-leaning entities. This
  pattern holds across presidential candidates, members of the U.S. Senate, and media
  organizations with ratings from AllSides. When qualitatively evaluating some of
  these outputs, there is evidence that particular facts are included or excluded
  based on the user’s political affiliation. These results illustrate that personalizing
  LLMs based on user demographics carry the same risks of affective polarization and
  filter bubbles that have been seen in other personalized internet technologies.
  This “failure mode" should be monitored closely as there are more attempts to monetize
  and personalize these models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lazovich23a
month: 0
tex_title: Filter bubbles and affective polarization in user-personalized large language
  model outputs
firstpage: 29
lastpage: 37
page: 29-37
order: 29
cycles: false
bibtex_author: Lazovich, Tomo
author:
- given: Tomo
  family: Lazovich
date: 2023-04-24
address:
container-title: 'Proceedings on "I Can''t Believe It''s Not Better: Failure  Modes
  in the Age of Foundation Models" at NeurIPS 2023 Workshops'
volume: '239'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 24
pdf: https://proceedings.mlr.press/v239/lazovich23a/lazovich23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
