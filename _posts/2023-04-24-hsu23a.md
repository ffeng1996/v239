---
title: Can Visual Scratchpads With Diagrammatic Abstractions Augment LLM Reasoning?
abstract: When humans reason about complex text-based questions, we leverage diagrammatic
  abstractions drawn on a visual scratchpad. In this paper, we introduce and explore
  the capabilities of Visual-Scratchpad, a method that augments a large language foundation
  model (LLM) with diagrammatic execution and readout. We enable the LLM to generate
  drawing commands and to readout abstractions from the resulting picture. The visual
  readout operation uses a visual foundation model, optionally finetuned with expert
  iteration. Here, we show that although Visual-Scratchpad outperforms an inference-only
  LLM, it surprisingly yields worse performance compared to a single finetuned LLM.
  Through experiments, we propose that this gap is due to the failure mode of vision
  foundation models in understanding abstractions in diagrams.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hsu23a
month: 0
tex_title: Can Visual Scratchpads With Diagrammatic Abstractions Augment LLM Reasoning?
firstpage: 21
lastpage: 28
page: 21-28
order: 21
cycles: false
bibtex_author: Hsu, Joy and Poesia, Gabriel and Wu, Jiajun and Goodman, Noah
author:
- given: Joy
  family: Hsu
- given: Gabriel
  family: Poesia
- given: Jiajun
  family: Wu
- given: Noah
  family: Goodman
date: 2023-04-24
address:
container-title: 'Proceedings on "I Can''t Believe It''s Not Better: Failure  Modes
  in the Age of Foundation Models" at NeurIPS 2023 Workshops'
volume: '239'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 24
pdf: https://proceedings.mlr.press/v239/hsu23a/hsu23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
