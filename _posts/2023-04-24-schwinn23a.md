---
title: 'Adversarial Attacks and Defenses in Large Language Models: Old and New Threats'
abstract: Over the past decade, there has been extensive research aimed at enhancing
  the robustness of neural networks, yet this problem remains vastly unsolved. Here,
  one major impediment has been the overestimation of the robustness of new defense
  approaches due to faulty defense evaluations. Flawed robustness evaluations necessitate
  rectifications in subsequent works, dangerously slowing down the research and providing
  a false sense of security. In this context, we will face substantial challenges
  associated with an impending adversarial arms race in natural language processing,
  specifically with closed-source Large Language Models (LLMs), such as ChatGPT, Google
  Bard, or Anthropic’s Claude. We provide a first set of prerequisites to improve
  the robustness assessment of new approaches and reduce the amount of faulty evaluations.
  Additionally, we identify embedding space attacks on LLMs as another viable threat
  model for the purposes of generating malicious content in open-sourced models. Finally,
  we demonstrate on a recently proposed defense that, without LLM-specific best practices
  in place, it is easy to overestimate the robustness of a new approach.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schwinn23a
month: 0
tex_title: 'Adversarial Attacks and Defenses in Large Language Models: Old and New
  Threats'
firstpage: 103
lastpage: 117
page: 103-117
order: 103
cycles: false
bibtex_author: Schwinn, Leo and Dobre, David and G{\"u}nnemann, Stephan and Gidel,
  Gauthier
author:
- given: Leo
  family: Schwinn
- given: David
  family: Dobre
- given: Stephan
  family: Günnemann
- given: Gauthier
  family: Gidel
date: 2023-04-24
address:
container-title: 'Proceedings on "I Can''t Believe It''s Not Better: Failure  Modes
  in the Age of Foundation Models" at NeurIPS 2022 Workshops'
volume: '239'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 24
pdf: https://proceedings.mlr.press/v239/schwinn23a/schwinn23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
